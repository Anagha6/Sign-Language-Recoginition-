# Sign Language Recoginition System

## CONTENTS


## INTRODUCTION
Inability to speak is considered to be true disability. People with this disability
use different modes to communicate with others, there are number of methods
available for their communication one such common method of
communication  is  sign  language.
Developing sign language application for deaf people can be very important,
as they’ll be able to communicate easily with even those who don’t understand
sign language.
Dumb people use hand signs to communicate, hence normal people face problem in recognizing their language by signs made. Hence there is a need of the systems which recognizes the different signs and conveys the information to the normal people.
In this presentation, we will be demonstrating a Computer Vision demo using YOLOv5 on the American Sign Language Dataset including 26 classes.

## **PROBLEM STATEMENT**
Our project aims at taking the basic step in bridging the
communication gap between normal people, deaf and dumb people using sign
language through image processing and computer vision.

## **DATA DESCRIPTION**
For this, We have used American Sign Language dataset that was collected from the gituhub. The dataset consists of 3399 images having 26 American Sign language alphabets. This dataset was used because of the availability of annotations which were required for training our model.The images for the training and testing sets are in train  and test files respectively, and additional information about each image is in labels.
    
      * American Sign Language
             
     




